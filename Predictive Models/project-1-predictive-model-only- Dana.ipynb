{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":189,"outputs":[{"output_type":"stream","text":"/kaggle/input/londonbikes/sample.csv\n/kaggle/input/londonbikes/test.csv\n/kaggle/input/londonbikes/train.csv\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Goal: Predict cnt\n- 8 features originally \n- timestamp must be divided to hour of day, day of month, month of year, and year \n- This adds two features: hour of day and month of year\n* 12223 examples in train, and 5191 examples in test."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport datetime\nimport tensorflow as tf\n\nplt.style.use('ggplot')\n","execution_count":190,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport glob\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":191,"outputs":[{"output_type":"stream","text":"/kaggle/input/londonbikes/sample.csv\n/kaggle/input/londonbikes/test.csv\n/kaggle/input/londonbikes/train.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.concat([pd.read_csv(f) for f in glob.glob(\"../input/londonbikes/train.csv\") ])\ntest_df = pd.concat([pd.read_csv(f) for f in glob.glob(\"../input/londonbikes/test.csv\") ])\n#data = pd.read_csv(\"train.csv\")\ntrain_df.head()","execution_count":192,"outputs":[{"output_type":"execute_result","execution_count":192,"data":{"text/plain":"             timestamp  cnt   t1   t2    hum  wind_speed  weather_code  \\\n0  2015-01-04 02:00:00  134  2.5  2.5   96.5         0.0           1.0   \n1  2015-01-04 07:00:00   75  1.0 -1.0  100.0         7.0           4.0   \n2  2015-01-04 08:00:00  131  1.5 -1.0   96.5         8.0           4.0   \n3  2015-01-04 09:00:00  301  2.0 -0.5  100.0         9.0           3.0   \n4  2015-01-04 10:00:00  528  3.0 -0.5   93.0        12.0           3.0   \n\n   is_holiday  is_weekend  season  \n0         0.0         1.0     3.0  \n1         0.0         1.0     3.0  \n2         0.0         1.0     3.0  \n3         0.0         1.0     3.0  \n4         0.0         1.0     3.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timestamp</th>\n      <th>cnt</th>\n      <th>t1</th>\n      <th>t2</th>\n      <th>hum</th>\n      <th>wind_speed</th>\n      <th>weather_code</th>\n      <th>is_holiday</th>\n      <th>is_weekend</th>\n      <th>season</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2015-01-04 02:00:00</td>\n      <td>134</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>96.5</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2015-01-04 07:00:00</td>\n      <td>75</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>100.0</td>\n      <td>7.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2015-01-04 08:00:00</td>\n      <td>131</td>\n      <td>1.5</td>\n      <td>-1.0</td>\n      <td>96.5</td>\n      <td>8.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2015-01-04 09:00:00</td>\n      <td>301</td>\n      <td>2.0</td>\n      <td>-0.5</td>\n      <td>100.0</td>\n      <td>9.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2015-01-04 10:00:00</td>\n      <td>528</td>\n      <td>3.0</td>\n      <td>-0.5</td>\n      <td>93.0</td>\n      <td>12.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Extracting hours, days, months, year"},{"metadata":{"trusted":true},"cell_type":"code","source":"##We fix the train_df \ntrain_df['timestamp'] = train_df['timestamp'] .apply(lambda x :datetime.datetime.strptime(str(x),'%Y-%m-%d %H:%M:%S'))\ntrain_df['month'] = train_df['timestamp'].apply(lambda x : float(str(x).split(' ')[0].split('-')[1]))\ntrain_df['day'] = train_df['timestamp'].apply(lambda x : float(str(x).split(' ')[0].split('-')[2]))\ntrain_df['hour'] = train_df['timestamp'].apply(lambda x : float(str(x).split(' ')[1].split(':')[0]))\n\n##We fix test_df \n\ntest_df['timestamp'] = test_df['timestamp'] .apply(lambda x :datetime.datetime.strptime(str(x),'%Y-%m-%d %H:%M:%S'))\ntest_df['month'] = test_df['timestamp'].apply(lambda x : float(str(x).split(' ')[0].split('-')[1]))\ntest_df['day'] = test_df['timestamp'].apply(lambda x : float(str(x).split(' ')[0].split('-')[2]))\ntest_df['hour'] = test_df['timestamp'].apply(lambda x : float(str(x).split(' ')[1].split(':')[0]))\n","execution_count":193,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We choose features to keep"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_timestamp = pd.Series(test_df['timestamp'])\n#3 features\ntrain_df.drop(columns=[\"timestamp\", \"t2\", \"wind_speed\",\"weather_code\", \"is_holiday\",\"is_weekend\", \"season\", \"month\", \"day\"],axis =1, inplace=True)\ntest_df.drop(columns=[ \"timestamp\",\"t2\", \"wind_speed\",\"weather_code\", \"is_holiday\",\"is_weekend\", \"season\", \"month\", \"day\"],axis=1, inplace=True)\n\n#4 features\n#train_df.drop(columns=[\"timestamp\", \"t2\", \"wind_speed\", \"is_holiday\",\"is_weekend\",\"season\", \"month\", \"day\"],axis =1, inplace=True)\n#test_df.drop(columns=[ \"timestamp\",\"t2\", \"wind_speed\", \"is_holiday\",\"is_weekend\", \"season\", \"month\", \"day\"],axis=1, inplace=True)\n\n\ntest_timestamp.head()","execution_count":194,"outputs":[{"output_type":"execute_result","execution_count":194,"data":{"text/plain":"0   2015-01-04 00:00:00\n1   2015-01-04 01:00:00\n2   2015-01-04 03:00:00\n3   2015-01-04 04:00:00\n4   2015-01-04 05:00:00\nName: timestamp, dtype: datetime64[ns]"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Starting with the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df_mean = train_df.mean()\nmean_cnt = train_df.mean()[0]\ntrain_df_std = train_df.std()\nstd_cnt =  train_df.std()[0]\ntrain_df_norm = (train_df - train_df_mean)/train_df_std\n\n###Normalizing test data \n\n#test_df_mean = test_df.mean()\n#test_df_std = test_df.std()\ntest_df_norm = (test_df - train_df_mean[1:4])/train_df_std[1:4]\n#test_df_norm = (test_df)\n\n##Split training dataset to two\nmsk = np.random.rand(len(train_df_norm))< 0.6 \ntrain_df_copy = train_df_norm\ntrain_df = train_df_copy[msk]\nvalid_df = train_df_copy[~msk]\n\n\n###To transform to numpy \n\ntrain_np = train_df.to_numpy()\nvalid_np = valid_df.to_numpy()\ntest_np = test_df_norm.to_numpy()\n\n\n##Independent variables are x; the features \n##Dependent varaibele is y; cnt \n\ntrain_x = train_np[:, -3:]\ntrain_y = train_np[:, :-3]\n\nvalid_x = valid_np[:, -3:]\nvalid_y = valid_np[:, :-3]\n\n#test_x = test_np[:, :-1]\n\n\n\n#cnt     1138.098830\n#t1        12.481742\n#hum       72.407081\n#hour      11.464289\n\n#train_df_norm.head()\nprint(train_np)\ntest_df_norm.head()\n","execution_count":195,"outputs":[{"output_type":"stream","text":"[[-0.93030101 -1.79972923  1.68920957 -1.37095208]\n [-0.98496472 -2.07018241  1.93460256 -0.64667573]\n [-0.93308052 -1.98003135  1.68920957 -0.50182046]\n ...\n [-0.0890359  -1.34897394  0.60246918  1.0915875 ]\n [-0.74222082 -1.25882288  0.42718847  1.38129804]\n [-0.8469157  -1.25882288  0.25190776  1.52615331]]\n","name":"stdout"},{"output_type":"execute_result","execution_count":195,"data":{"text/plain":"         t1       hum      hour\n0 -1.709578  1.443817 -1.660663\n1 -1.709578  1.443817 -1.515807\n2 -1.889880  1.934603 -1.226097\n3 -1.889880  1.443817 -1.081242\n4 -1.889880  1.443817 -0.936386","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>t1</th>\n      <th>hum</th>\n      <th>hour</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.709578</td>\n      <td>1.443817</td>\n      <td>-1.660663</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-1.709578</td>\n      <td>1.443817</td>\n      <td>-1.515807</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.889880</td>\n      <td>1.934603</td>\n      <td>-1.226097</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.889880</td>\n      <td>1.443817</td>\n      <td>-1.081242</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.889880</td>\n      <td>1.443817</td>\n      <td>-0.936386</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n#train_dataset = train_dataset.apply(tf.contrib.data.unbatch())\n#dataset = dataset.batch(batch_size)\n\nmodel = tf.keras.Sequential()\n\nmodel.add(tf.keras.layers.Dense(units=128, input_shape=(3,), activation = 'relu'))\nmodel.add(tf.keras.layers.Dense(units=128, activation = 'relu'))\nmodel.add(tf.keras.layers.Dense(units=128, activation = 'relu'))\nmodel.add(tf.keras.layers.Dense(units=128, activation = 'relu'))\nmodel.add(tf.keras.layers.Dense(units=128, activation = 'relu'))\nmodel.add(tf.keras.layers.Dropout(0.3))\nmodel.add(tf.keras.layers.Dense(units=1))\n\n\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.00005),\n    loss='mean_squared_error',metrics=[tf.keras.metrics.RootMeanSquaredError()])\n\ntrain_ds = tf.data.Dataset.from_tensor_slices((train_x, train_y)).shuffle(50).batch(1000)\nvalid_ds = tf.data.Dataset.from_tensor_slices((valid_x, valid_y)).shuffle(50).batch(1000)\n\n\nhistory = model.fit(train_ds, validation_data= valid_ds, epochs=800,shuffle=True)\n","execution_count":null,"outputs":[{"output_type":"stream","text":"Epoch 1/800\n8/8 [==============================] - 0s 23ms/step - loss: 1.0115 - root_mean_squared_error: 1.0057 - val_loss: 1.0180 - val_root_mean_squared_error: 1.0090\nEpoch 2/800\n8/8 [==============================] - 0s 12ms/step - loss: 0.9914 - root_mean_squared_error: 0.9957 - val_loss: 0.9980 - val_root_mean_squared_error: 0.9990\nEpoch 3/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.9714 - root_mean_squared_error: 0.9856 - val_loss: 0.9791 - val_root_mean_squared_error: 0.9895\nEpoch 4/800\n8/8 [==============================] - 0s 14ms/step - loss: 0.9529 - root_mean_squared_error: 0.9761 - val_loss: 0.9605 - val_root_mean_squared_error: 0.9801\nEpoch 5/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.9331 - root_mean_squared_error: 0.9660 - val_loss: 0.9415 - val_root_mean_squared_error: 0.9703\nEpoch 6/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.9138 - root_mean_squared_error: 0.9559 - val_loss: 0.9217 - val_root_mean_squared_error: 0.9600\nEpoch 7/800\n8/8 [==============================] - 0s 14ms/step - loss: 0.8958 - root_mean_squared_error: 0.9465 - val_loss: 0.9008 - val_root_mean_squared_error: 0.9491\nEpoch 8/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.8743 - root_mean_squared_error: 0.9350 - val_loss: 0.8787 - val_root_mean_squared_error: 0.9374\nEpoch 9/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.8523 - root_mean_squared_error: 0.9232 - val_loss: 0.8558 - val_root_mean_squared_error: 0.9251\nEpoch 10/800\n8/8 [==============================] - 0s 15ms/step - loss: 0.8300 - root_mean_squared_error: 0.9110 - val_loss: 0.8325 - val_root_mean_squared_error: 0.9124\nEpoch 11/800\n8/8 [==============================] - 0s 16ms/step - loss: 0.8069 - root_mean_squared_error: 0.8983 - val_loss: 0.8090 - val_root_mean_squared_error: 0.8995\nEpoch 12/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.7848 - root_mean_squared_error: 0.8859 - val_loss: 0.7856 - val_root_mean_squared_error: 0.8863\nEpoch 13/800\n8/8 [==============================] - 0s 14ms/step - loss: 0.7602 - root_mean_squared_error: 0.8719 - val_loss: 0.7623 - val_root_mean_squared_error: 0.8731\nEpoch 14/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.7379 - root_mean_squared_error: 0.8590 - val_loss: 0.7399 - val_root_mean_squared_error: 0.8602\nEpoch 15/800\n8/8 [==============================] - 0s 12ms/step - loss: 0.7188 - root_mean_squared_error: 0.8478 - val_loss: 0.7188 - val_root_mean_squared_error: 0.8478\nEpoch 16/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.6986 - root_mean_squared_error: 0.8358 - val_loss: 0.6997 - val_root_mean_squared_error: 0.8365\nEpoch 17/800\n8/8 [==============================] - 0s 14ms/step - loss: 0.6838 - root_mean_squared_error: 0.8269 - val_loss: 0.6830 - val_root_mean_squared_error: 0.8265\nEpoch 18/800\n8/8 [==============================] - 0s 14ms/step - loss: 0.6662 - root_mean_squared_error: 0.8162 - val_loss: 0.6689 - val_root_mean_squared_error: 0.8179\nEpoch 19/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.6571 - root_mean_squared_error: 0.8106 - val_loss: 0.6572 - val_root_mean_squared_error: 0.8107\nEpoch 20/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.6474 - root_mean_squared_error: 0.8046 - val_loss: 0.6477 - val_root_mean_squared_error: 0.8048\nEpoch 21/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.6361 - root_mean_squared_error: 0.7976 - val_loss: 0.6399 - val_root_mean_squared_error: 0.7999\nEpoch 22/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.6287 - root_mean_squared_error: 0.7929 - val_loss: 0.6333 - val_root_mean_squared_error: 0.7958\nEpoch 23/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.6274 - root_mean_squared_error: 0.7921 - val_loss: 0.6278 - val_root_mean_squared_error: 0.7923\nEpoch 24/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.6253 - root_mean_squared_error: 0.7908 - val_loss: 0.6230 - val_root_mean_squared_error: 0.7893\nEpoch 25/800\n8/8 [==============================] - 0s 14ms/step - loss: 0.6180 - root_mean_squared_error: 0.7861 - val_loss: 0.6186 - val_root_mean_squared_error: 0.7865\nEpoch 26/800\n8/8 [==============================] - 0s 12ms/step - loss: 0.6160 - root_mean_squared_error: 0.7849 - val_loss: 0.6145 - val_root_mean_squared_error: 0.7839\nEpoch 27/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.6106 - root_mean_squared_error: 0.7814 - val_loss: 0.6108 - val_root_mean_squared_error: 0.7815\nEpoch 28/800\n8/8 [==============================] - 0s 12ms/step - loss: 0.6032 - root_mean_squared_error: 0.7767 - val_loss: 0.6072 - val_root_mean_squared_error: 0.7792\nEpoch 29/800\n8/8 [==============================] - 0s 12ms/step - loss: 0.6040 - root_mean_squared_error: 0.7772 - val_loss: 0.6038 - val_root_mean_squared_error: 0.7771\nEpoch 30/800\n8/8 [==============================] - 0s 12ms/step - loss: 0.5986 - root_mean_squared_error: 0.7737 - val_loss: 0.6007 - val_root_mean_squared_error: 0.7751\nEpoch 31/800\n8/8 [==============================] - 0s 12ms/step - loss: 0.5995 - root_mean_squared_error: 0.7743 - val_loss: 0.5977 - val_root_mean_squared_error: 0.7731\nEpoch 32/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.5956 - root_mean_squared_error: 0.7717 - val_loss: 0.5948 - val_root_mean_squared_error: 0.7713\nEpoch 33/800\n8/8 [==============================] - 0s 12ms/step - loss: 0.5894 - root_mean_squared_error: 0.7677 - val_loss: 0.5921 - val_root_mean_squared_error: 0.7695\nEpoch 34/800\n8/8 [==============================] - 0s 12ms/step - loss: 0.5880 - root_mean_squared_error: 0.7668 - val_loss: 0.5894 - val_root_mean_squared_error: 0.7677\nEpoch 35/800\n8/8 [==============================] - 0s 12ms/step - loss: 0.5868 - root_mean_squared_error: 0.7660 - val_loss: 0.5869 - val_root_mean_squared_error: 0.7661\nEpoch 36/800\n8/8 [==============================] - 0s 11ms/step - loss: 0.5832 - root_mean_squared_error: 0.7637 - val_loss: 0.5845 - val_root_mean_squared_error: 0.7645\nEpoch 37/800\n8/8 [==============================] - 0s 12ms/step - loss: 0.5814 - root_mean_squared_error: 0.7625 - val_loss: 0.5821 - val_root_mean_squared_error: 0.7630\nEpoch 38/800\n8/8 [==============================] - 0s 12ms/step - loss: 0.5817 - root_mean_squared_error: 0.7627 - val_loss: 0.5799 - val_root_mean_squared_error: 0.7615\nEpoch 39/800\n8/8 [==============================] - 0s 11ms/step - loss: 0.5743 - root_mean_squared_error: 0.7578 - val_loss: 0.5779 - val_root_mean_squared_error: 0.7602\nEpoch 40/800\n8/8 [==============================] - 0s 12ms/step - loss: 0.5769 - root_mean_squared_error: 0.7596 - val_loss: 0.5758 - val_root_mean_squared_error: 0.7588\nEpoch 41/800\n8/8 [==============================] - 0s 11ms/step - loss: 0.5770 - root_mean_squared_error: 0.7596 - val_loss: 0.5738 - val_root_mean_squared_error: 0.7575\nEpoch 42/800\n8/8 [==============================] - 0s 12ms/step - loss: 0.5723 - root_mean_squared_error: 0.7565 - val_loss: 0.5718 - val_root_mean_squared_error: 0.7561\nEpoch 43/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.5694 - root_mean_squared_error: 0.7546 - val_loss: 0.5698 - val_root_mean_squared_error: 0.7548\nEpoch 44/800\n8/8 [==============================] - 0s 14ms/step - loss: 0.5707 - root_mean_squared_error: 0.7554 - val_loss: 0.5679 - val_root_mean_squared_error: 0.7536\nEpoch 45/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.5681 - root_mean_squared_error: 0.7537 - val_loss: 0.5659 - val_root_mean_squared_error: 0.7523\nEpoch 46/800\n8/8 [==============================] - 0s 14ms/step - loss: 0.5645 - root_mean_squared_error: 0.7514 - val_loss: 0.5640 - val_root_mean_squared_error: 0.7510\nEpoch 47/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.5596 - root_mean_squared_error: 0.7481 - val_loss: 0.5622 - val_root_mean_squared_error: 0.7498\nEpoch 48/800\n8/8 [==============================] - 0s 14ms/step - loss: 0.5603 - root_mean_squared_error: 0.7485 - val_loss: 0.5605 - val_root_mean_squared_error: 0.7487\n","name":"stdout"},{"output_type":"stream","text":"Epoch 49/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.5588 - root_mean_squared_error: 0.7475 - val_loss: 0.5587 - val_root_mean_squared_error: 0.7475\nEpoch 50/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.5553 - root_mean_squared_error: 0.7452 - val_loss: 0.5568 - val_root_mean_squared_error: 0.7462\nEpoch 51/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.5545 - root_mean_squared_error: 0.7446 - val_loss: 0.5550 - val_root_mean_squared_error: 0.7450\nEpoch 52/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.5527 - root_mean_squared_error: 0.7434 - val_loss: 0.5533 - val_root_mean_squared_error: 0.7438\nEpoch 53/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.5525 - root_mean_squared_error: 0.7433 - val_loss: 0.5516 - val_root_mean_squared_error: 0.7427\nEpoch 54/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.5487 - root_mean_squared_error: 0.7408 - val_loss: 0.5498 - val_root_mean_squared_error: 0.7415\nEpoch 55/800\n8/8 [==============================] - 0s 14ms/step - loss: 0.5474 - root_mean_squared_error: 0.7399 - val_loss: 0.5482 - val_root_mean_squared_error: 0.7404\nEpoch 56/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.5451 - root_mean_squared_error: 0.7383 - val_loss: 0.5465 - val_root_mean_squared_error: 0.7393\nEpoch 57/800\n8/8 [==============================] - 0s 14ms/step - loss: 0.5468 - root_mean_squared_error: 0.7394 - val_loss: 0.5448 - val_root_mean_squared_error: 0.7381\nEpoch 58/800\n8/8 [==============================] - 0s 12ms/step - loss: 0.5469 - root_mean_squared_error: 0.7395 - val_loss: 0.5431 - val_root_mean_squared_error: 0.7370\nEpoch 59/800\n8/8 [==============================] - 0s 12ms/step - loss: 0.5409 - root_mean_squared_error: 0.7355 - val_loss: 0.5414 - val_root_mean_squared_error: 0.7358\nEpoch 60/800\n8/8 [==============================] - 0s 14ms/step - loss: 0.5409 - root_mean_squared_error: 0.7355 - val_loss: 0.5398 - val_root_mean_squared_error: 0.7347\nEpoch 61/800\n8/8 [==============================] - 0s 14ms/step - loss: 0.5380 - root_mean_squared_error: 0.7335 - val_loss: 0.5383 - val_root_mean_squared_error: 0.7337\nEpoch 62/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.5404 - root_mean_squared_error: 0.7351 - val_loss: 0.5367 - val_root_mean_squared_error: 0.7326\nEpoch 63/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.5332 - root_mean_squared_error: 0.7302 - val_loss: 0.5351 - val_root_mean_squared_error: 0.7315\nEpoch 64/800\n8/8 [==============================] - 0s 14ms/step - loss: 0.5353 - root_mean_squared_error: 0.7316 - val_loss: 0.5335 - val_root_mean_squared_error: 0.7304\nEpoch 65/800\n8/8 [==============================] - 0s 14ms/step - loss: 0.5317 - root_mean_squared_error: 0.7291 - val_loss: 0.5320 - val_root_mean_squared_error: 0.7293\nEpoch 66/800\n8/8 [==============================] - 0s 14ms/step - loss: 0.5304 - root_mean_squared_error: 0.7283 - val_loss: 0.5304 - val_root_mean_squared_error: 0.7283\nEpoch 67/800\n8/8 [==============================] - 0s 12ms/step - loss: 0.5290 - root_mean_squared_error: 0.7273 - val_loss: 0.5288 - val_root_mean_squared_error: 0.7272\nEpoch 68/800\n8/8 [==============================] - 0s 12ms/step - loss: 0.5276 - root_mean_squared_error: 0.7264 - val_loss: 0.5272 - val_root_mean_squared_error: 0.7261\nEpoch 69/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.5245 - root_mean_squared_error: 0.7242 - val_loss: 0.5256 - val_root_mean_squared_error: 0.7250\nEpoch 70/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.5266 - root_mean_squared_error: 0.7257 - val_loss: 0.5240 - val_root_mean_squared_error: 0.7239\nEpoch 71/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.5221 - root_mean_squared_error: 0.7226 - val_loss: 0.5224 - val_root_mean_squared_error: 0.7228\nEpoch 72/800\n8/8 [==============================] - 0s 11ms/step - loss: 0.5225 - root_mean_squared_error: 0.7228 - val_loss: 0.5209 - val_root_mean_squared_error: 0.7217\nEpoch 73/800\n8/8 [==============================] - 0s 14ms/step - loss: 0.5194 - root_mean_squared_error: 0.7207 - val_loss: 0.5193 - val_root_mean_squared_error: 0.7207\nEpoch 74/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.5185 - root_mean_squared_error: 0.7201 - val_loss: 0.5179 - val_root_mean_squared_error: 0.7196\nEpoch 75/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.5195 - root_mean_squared_error: 0.7208 - val_loss: 0.5164 - val_root_mean_squared_error: 0.7186\nEpoch 76/800\n8/8 [==============================] - 0s 14ms/step - loss: 0.5164 - root_mean_squared_error: 0.7186 - val_loss: 0.5150 - val_root_mean_squared_error: 0.7176\nEpoch 77/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.5128 - root_mean_squared_error: 0.7161 - val_loss: 0.5134 - val_root_mean_squared_error: 0.7165\nEpoch 78/800\n8/8 [==============================] - 0s 14ms/step - loss: 0.5129 - root_mean_squared_error: 0.7161 - val_loss: 0.5118 - val_root_mean_squared_error: 0.7154\nEpoch 79/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.5119 - root_mean_squared_error: 0.7155 - val_loss: 0.5104 - val_root_mean_squared_error: 0.7144\nEpoch 80/800\n8/8 [==============================] - 0s 14ms/step - loss: 0.5108 - root_mean_squared_error: 0.7147 - val_loss: 0.5092 - val_root_mean_squared_error: 0.7136\nEpoch 81/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.5058 - root_mean_squared_error: 0.7112 - val_loss: 0.5078 - val_root_mean_squared_error: 0.7126\nEpoch 82/800\n8/8 [==============================] - 0s 14ms/step - loss: 0.5076 - root_mean_squared_error: 0.7125 - val_loss: 0.5062 - val_root_mean_squared_error: 0.7115\nEpoch 83/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.5059 - root_mean_squared_error: 0.7112 - val_loss: 0.5048 - val_root_mean_squared_error: 0.7105\nEpoch 84/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.5033 - root_mean_squared_error: 0.7094 - val_loss: 0.5036 - val_root_mean_squared_error: 0.7096\nEpoch 85/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.5029 - root_mean_squared_error: 0.7091 - val_loss: 0.5022 - val_root_mean_squared_error: 0.7087\nEpoch 86/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.5009 - root_mean_squared_error: 0.7077 - val_loss: 0.5009 - val_root_mean_squared_error: 0.7077\nEpoch 87/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.5003 - root_mean_squared_error: 0.7073 - val_loss: 0.4995 - val_root_mean_squared_error: 0.7067\nEpoch 88/800\n8/8 [==============================] - 0s 14ms/step - loss: 0.4986 - root_mean_squared_error: 0.7061 - val_loss: 0.4982 - val_root_mean_squared_error: 0.7058\nEpoch 89/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.4990 - root_mean_squared_error: 0.7064 - val_loss: 0.4967 - val_root_mean_squared_error: 0.7048\nEpoch 90/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.4973 - root_mean_squared_error: 0.7052 - val_loss: 0.4953 - val_root_mean_squared_error: 0.7037\nEpoch 91/800\n8/8 [==============================] - 0s 14ms/step - loss: 0.4933 - root_mean_squared_error: 0.7023 - val_loss: 0.4940 - val_root_mean_squared_error: 0.7028\nEpoch 92/800\n8/8 [==============================] - 0s 14ms/step - loss: 0.4935 - root_mean_squared_error: 0.7025 - val_loss: 0.4927 - val_root_mean_squared_error: 0.7020\nEpoch 93/800\n8/8 [==============================] - 0s 14ms/step - loss: 0.4932 - root_mean_squared_error: 0.7023 - val_loss: 0.4915 - val_root_mean_squared_error: 0.7011\nEpoch 94/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.4939 - root_mean_squared_error: 0.7027 - val_loss: 0.4903 - val_root_mean_squared_error: 0.7002\nEpoch 95/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.4914 - root_mean_squared_error: 0.7010 - val_loss: 0.4888 - val_root_mean_squared_error: 0.6992\nEpoch 96/800\n8/8 [==============================] - 0s 12ms/step - loss: 0.4909 - root_mean_squared_error: 0.7006 - val_loss: 0.4876 - val_root_mean_squared_error: 0.6983\n","name":"stdout"},{"output_type":"stream","text":"Epoch 97/800\n8/8 [==============================] - 0s 12ms/step - loss: 0.4898 - root_mean_squared_error: 0.6998 - val_loss: 0.4864 - val_root_mean_squared_error: 0.6974\nEpoch 98/800\n8/8 [==============================] - 0s 12ms/step - loss: 0.4855 - root_mean_squared_error: 0.6968 - val_loss: 0.4850 - val_root_mean_squared_error: 0.6964\nEpoch 99/800\n8/8 [==============================] - 0s 12ms/step - loss: 0.4831 - root_mean_squared_error: 0.6950 - val_loss: 0.4835 - val_root_mean_squared_error: 0.6954\nEpoch 100/800\n8/8 [==============================] - 0s 12ms/step - loss: 0.4826 - root_mean_squared_error: 0.6947 - val_loss: 0.4823 - val_root_mean_squared_error: 0.6945\nEpoch 101/800\n8/8 [==============================] - 0s 16ms/step - loss: 0.4824 - root_mean_squared_error: 0.6945 - val_loss: 0.4811 - val_root_mean_squared_error: 0.6936\nEpoch 102/800\n8/8 [==============================] - 0s 12ms/step - loss: 0.4811 - root_mean_squared_error: 0.6936 - val_loss: 0.4797 - val_root_mean_squared_error: 0.6926\nEpoch 103/800\n8/8 [==============================] - 0s 12ms/step - loss: 0.4794 - root_mean_squared_error: 0.6924 - val_loss: 0.4784 - val_root_mean_squared_error: 0.6917\nEpoch 104/800\n8/8 [==============================] - 0s 12ms/step - loss: 0.4797 - root_mean_squared_error: 0.6926 - val_loss: 0.4771 - val_root_mean_squared_error: 0.6907\nEpoch 105/800\n8/8 [==============================] - 0s 12ms/step - loss: 0.4792 - root_mean_squared_error: 0.6923 - val_loss: 0.4757 - val_root_mean_squared_error: 0.6897\nEpoch 106/800\n8/8 [==============================] - 0s 21ms/step - loss: 0.4766 - root_mean_squared_error: 0.6903 - val_loss: 0.4744 - val_root_mean_squared_error: 0.6888\nEpoch 107/800\n8/8 [==============================] - 0s 14ms/step - loss: 0.4745 - root_mean_squared_error: 0.6889 - val_loss: 0.4731 - val_root_mean_squared_error: 0.6878\nEpoch 108/800\n8/8 [==============================] - 0s 16ms/step - loss: 0.4765 - root_mean_squared_error: 0.6903 - val_loss: 0.4717 - val_root_mean_squared_error: 0.6868\nEpoch 109/800\n8/8 [==============================] - 0s 15ms/step - loss: 0.4703 - root_mean_squared_error: 0.6858 - val_loss: 0.4704 - val_root_mean_squared_error: 0.6858\nEpoch 110/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.4709 - root_mean_squared_error: 0.6862 - val_loss: 0.4689 - val_root_mean_squared_error: 0.6848\nEpoch 111/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.4698 - root_mean_squared_error: 0.6854 - val_loss: 0.4675 - val_root_mean_squared_error: 0.6837\nEpoch 112/800\n8/8 [==============================] - 0s 15ms/step - loss: 0.4699 - root_mean_squared_error: 0.6855 - val_loss: 0.4662 - val_root_mean_squared_error: 0.6828\nEpoch 113/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.4638 - root_mean_squared_error: 0.6810 - val_loss: 0.4644 - val_root_mean_squared_error: 0.6815\nEpoch 114/800\n8/8 [==============================] - 0s 16ms/step - loss: 0.4655 - root_mean_squared_error: 0.6823 - val_loss: 0.4630 - val_root_mean_squared_error: 0.6805\nEpoch 115/800\n8/8 [==============================] - 0s 14ms/step - loss: 0.4628 - root_mean_squared_error: 0.6803 - val_loss: 0.4617 - val_root_mean_squared_error: 0.6795\nEpoch 116/800\n8/8 [==============================] - 0s 15ms/step - loss: 0.4623 - root_mean_squared_error: 0.6799 - val_loss: 0.4602 - val_root_mean_squared_error: 0.6784\nEpoch 117/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.4616 - root_mean_squared_error: 0.6794 - val_loss: 0.4590 - val_root_mean_squared_error: 0.6775\nEpoch 118/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.4608 - root_mean_squared_error: 0.6788 - val_loss: 0.4574 - val_root_mean_squared_error: 0.6763\nEpoch 119/800\n8/8 [==============================] - 0s 14ms/step - loss: 0.4587 - root_mean_squared_error: 0.6773 - val_loss: 0.4558 - val_root_mean_squared_error: 0.6751\nEpoch 120/800\n8/8 [==============================] - 0s 14ms/step - loss: 0.4573 - root_mean_squared_error: 0.6762 - val_loss: 0.4543 - val_root_mean_squared_error: 0.6740\nEpoch 121/800\n8/8 [==============================] - 0s 14ms/step - loss: 0.4572 - root_mean_squared_error: 0.6762 - val_loss: 0.4526 - val_root_mean_squared_error: 0.6728\nEpoch 122/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.4527 - root_mean_squared_error: 0.6728 - val_loss: 0.4510 - val_root_mean_squared_error: 0.6716\nEpoch 123/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.4524 - root_mean_squared_error: 0.6726 - val_loss: 0.4495 - val_root_mean_squared_error: 0.6704\nEpoch 124/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.4503 - root_mean_squared_error: 0.6711 - val_loss: 0.4478 - val_root_mean_squared_error: 0.6692\nEpoch 125/800\n8/8 [==============================] - 0s 14ms/step - loss: 0.4470 - root_mean_squared_error: 0.6686 - val_loss: 0.4462 - val_root_mean_squared_error: 0.6680\nEpoch 126/800\n8/8 [==============================] - 0s 14ms/step - loss: 0.4492 - root_mean_squared_error: 0.6702 - val_loss: 0.4446 - val_root_mean_squared_error: 0.6667\nEpoch 127/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.4458 - root_mean_squared_error: 0.6677 - val_loss: 0.4431 - val_root_mean_squared_error: 0.6656\nEpoch 128/800\n8/8 [==============================] - 0s 14ms/step - loss: 0.4444 - root_mean_squared_error: 0.6666 - val_loss: 0.4414 - val_root_mean_squared_error: 0.6644\nEpoch 129/800\n8/8 [==============================] - 0s 14ms/step - loss: 0.4425 - root_mean_squared_error: 0.6652 - val_loss: 0.4398 - val_root_mean_squared_error: 0.6632\nEpoch 130/800\n8/8 [==============================] - 0s 14ms/step - loss: 0.4438 - root_mean_squared_error: 0.6662 - val_loss: 0.4381 - val_root_mean_squared_error: 0.6619\nEpoch 131/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.4413 - root_mean_squared_error: 0.6643 - val_loss: 0.4364 - val_root_mean_squared_error: 0.6606\nEpoch 132/800\n8/8 [==============================] - 0s 15ms/step - loss: 0.4377 - root_mean_squared_error: 0.6616 - val_loss: 0.4346 - val_root_mean_squared_error: 0.6593\nEpoch 133/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.4351 - root_mean_squared_error: 0.6596 - val_loss: 0.4329 - val_root_mean_squared_error: 0.6580\nEpoch 134/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.4361 - root_mean_squared_error: 0.6604 - val_loss: 0.4312 - val_root_mean_squared_error: 0.6566\nEpoch 135/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.4323 - root_mean_squared_error: 0.6575 - val_loss: 0.4292 - val_root_mean_squared_error: 0.6551\nEpoch 136/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.4321 - root_mean_squared_error: 0.6573 - val_loss: 0.4275 - val_root_mean_squared_error: 0.6538\nEpoch 137/800\n8/8 [==============================] - 0s 13ms/step - loss: 0.4319 - root_mean_squared_error: 0.6572 - val_loss: 0.4258 - val_root_mean_squared_error: 0.6525\nEpoch 138/800\n8/8 [==============================] - 0s 14ms/step - loss: 0.4257 - root_mean_squared_error: 0.6525 - val_loss: 0.4238 - val_root_mean_squared_error: 0.6510\nEpoch 139/800\n8/8 [==============================] - 0s 12ms/step - loss: 0.4257 - root_mean_squared_error: 0.6525 - val_loss: 0.4220 - val_root_mean_squared_error: 0.6496\nEpoch 140/800\n8/8 [==============================] - 0s 14ms/step - loss: 0.4238 - root_mean_squared_error: 0.6510 - val_loss: 0.4200 - val_root_mean_squared_error: 0.6481\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef plot_the_loss_curve(epochs, rmse):\n    plt.figure()\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Root Mean Squared Error\")\n    plt.plot(epochs, rmse, label=\"Loss\")\n    plt.legend()\n    plt.ylim([rmse.min()*0.94, rmse.max()* 1.05])\n    plt.show() \n    \n    \n#history = model.fit(train_df_norm.batch(batch_size),validation_data = test_df_norm.batch(batch_size),\n #         epochs=epochs, shuffle=True )\nepochs = history.epoch\n\n# Isolate the mean absolute error for each epoch.\nhist = pd.DataFrame(history.history)\nrmse = hist[\"root_mean_squared_error\"]\n\nplot_the_loss_curve(epochs, rmse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Root Mean Squared Error\")\n\nplt.plot(epochs, hist.root_mean_squared_error, label =\"train rmse\")\nplt.plot(epochs, hist.val_root_mean_squared_error, label =\"validation rmse\")\nplt.legend()\nplt.ylim([hist.root_mean_squared_error.min()*0.94, hist.root_mean_squared_error.max()*1.05])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(test_np)\n\n##This gives us the normalized predictions since cnt in train was normalized too\npredictions_df_norm = pd.DataFrame(predictions)\n#predictions_df_mean = predictions_df_norm.mean()\n#predictions_df_std = predictions_df_norm.std()\n#predictions_df = (predictions_df_norm * predictions_df_std)+ predictions_df_mean\n\npredictions_df = (predictions_df_norm * std_cnt)+ mean_cnt\nsubmission = pd.DataFrame (columns = ['Timestamp','cnt'])\n#test_timestamp = test_timestamp.to_numpy()\ntest_timestamp.tolist()\n#test_timestamp = pd.Series (test_timestamp)\nsubmission['Timestamp'] = test_timestamp\n#submission['cnt'] = predictions_df\n#predictions_np = predictions_df.to_numpy()\n\nsubmission['cnt'] = predictions_df\nsubmission.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_df.mean()  #1152.748535","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_cnt  #1138.0988300744498","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission_Dana.csv',index=False)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}